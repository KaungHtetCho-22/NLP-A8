{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: peft==0.7.1 in /home/koala/.local/lib/python3.11/site-packages (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from peft==0.7.1) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (23.2)\n",
      "Requirement already satisfied: psutil in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (2.1.2)\n",
      "Requirement already satisfied: transformers in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (0.25.0)\n",
      "Requirement already satisfied: safetensors in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/koala/.local/lib/python3.11/site-packages (from peft==0.7.1) (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/koala/.local/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/koala/.local/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/koala/.local/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/koala/.local/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (1.12)\n",
      "Requirement already satisfied: networkx in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/koala/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.7.1) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/koala/.local/lib/python3.11/site-packages (from transformers->peft==0.7.1) (2023.3.23)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/koala/.local/lib/python3.11/site-packages (from transformers->peft==0.7.1) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/koala/.local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/koala/.local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/koala/.local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/koala/.local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/koala/.local/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.7.1) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trl==0.7.4 in /home/koala/.local/lib/python3.11/site-packages (0.7.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/koala/.local/lib/python3.11/site-packages (from trl==0.7.4) (2.1.2)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /home/koala/.local/lib/python3.11/site-packages (from trl==0.7.4) (4.36.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/lib/python3/dist-packages (from trl==0.7.4) (1.24.2)\n",
      "Requirement already satisfied: accelerate in /home/koala/.local/lib/python3.11/site-packages (from trl==0.7.4) (0.25.0)\n",
      "Requirement already satisfied: datasets in /home/koala/.local/lib/python3.11/site-packages (from trl==0.7.4) (2.16.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/koala/.local/lib/python3.11/site-packages (from trl==0.7.4) (0.7.3)\n",
      "Requirement already satisfied: filelock in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (1.12)\n",
      "Requirement already satisfied: networkx in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/koala/.local/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/koala/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl==0.7.4) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (2023.3.23)\n",
      "Requirement already satisfied: requests in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/koala/.local/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (4.65.0)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/koala/.local/lib/python3.11/site-packages (from tyro>=0.5.11->trl==0.7.4) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/lib/python3/dist-packages (from tyro>=0.5.11->trl==0.7.4) (13.3.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/koala/.local/lib/python3.11/site-packages (from tyro>=0.5.11->trl==0.7.4) (1.7.1)\n",
      "Requirement already satisfied: psutil in /home/koala/.local/lib/python3.11/site-packages (from accelerate->trl==0.7.4) (5.9.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/koala/.local/lib/python3.11/site-packages (from datasets->trl==0.7.4) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/koala/.local/lib/python3.11/site-packages (from datasets->trl==0.7.4) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/koala/.local/lib/python3.11/site-packages (from datasets->trl==0.7.4) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/koala/.local/lib/python3.11/site-packages (from datasets->trl==0.7.4) (2.0.0)\n",
      "Requirement already satisfied: xxhash in /home/koala/.local/lib/python3.11/site-packages (from datasets->trl==0.7.4) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/koala/.local/lib/python3.11/site-packages (from datasets->trl==0.7.4) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/koala/.local/lib/python3.11/site-packages (from datasets->trl==0.7.4) (3.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/koala/.local/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/koala/.local/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/koala/.local/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/koala/.local/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/koala/.local/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/koala/.local/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/koala/.local/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/koala/.local/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/koala/.local/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/koala/.local/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /home/koala/.local/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/lib/python3/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.4.0->trl==0.7.4) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3/dist-packages (from pandas->datasets->trl==0.7.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/koala/.local/lib/python3.11/site-packages (from pandas->datasets->trl==0.7.4) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/koala/.local/lib/python3.11/site-packages (from pandas->datasets->trl==0.7.4) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/koala/.local/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl==0.7.4) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/lib/python3/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer==4.36.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer==4.36.2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install peft==0.7.1\n",
    "!pip3 install trl==0.7.4\n",
    "!pip3 install transformer==4.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koala/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-25 23:31:47.067677: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-25 23:31:47.097825: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 23:31:47.666721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/koala/.local/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import trl\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Alpaca dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: load the json file\n",
    "\n",
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "json_file_path = \"alpaca_data.json\"\n",
    "\n",
    "alpaca_dataset = Dataset.from_json(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'instruction'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koala/.local/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for tatsu-lab/alpaca_eval contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tatsu-lab/alpaca_eval\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output', 'generator', 'dataset'],\n",
       "    num_rows: 805\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "alpaca_eval_dataset = load_dataset(\"tatsu-lab/alpaca_eval\", split='eval')\n",
    "alpaca_eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Load the model & Tokenizer\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map = 'auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### Question: Give three tips for staying healthy.\\n ### Answer: 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n",
       " '### Question: What are the three primary colors?\\n ### Answer: The three primary colors are red, blue, and yellow.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "#check instruction-prompt\n",
    "formatting_prompts_func(alpaca_dataset[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForCompletionOnlyLM(tokenizer=GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "response_template = \" ### Answer:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = min(tokenizer.model_max_length, 64)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 25767.50 examples/s]\n",
      "Map: 100%|██████████| 50/50 [00:00<00:00, 8917.22 examples/s]\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:40<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 40.1778, 'train_samples_per_second': 74.668, 'train_steps_per_second': 9.334, 'train_loss': 2.618673177083333, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=2.618673177083333, metrics={'train_runtime': 40.1778, 'train_samples_per_second': 74.668, 'train_steps_per_second': 9.334, 'train_loss': 2.618673177083333, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2: Define the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=alpaca_dataset.select(range(1000)),\n",
    "    eval_dataset=alpaca_eval_dataset.select(range(50)),\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "\n",
    "trainer.train() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 47.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.6091973781585693,\n",
       " 'eval_runtime': 0.1796,\n",
       " 'eval_samples_per_second': 278.358,\n",
       " 'eval_steps_per_second': 38.97,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Explain me about python programming. It’s a powerful and powerful programming language that can be used to solve complex problems in a variety of different languages and languages. Python is an open-source language, which allows programmers to quickly and easily implement complex programming languages without having to rely on proprietary software or hardware to do the work. Additionally, it is easy to use and has the potential to revolutionize the way programming is written and used in many languages, such as Python, C++, and C#. The Python language is also widely used for developing applications and applications, allowing developers to create and maintain applications that are easily accessible to the general public. Furthermore, the language has a wide range of features, including support for JavaScript and JavaScript, as well as a number of other features. For example, there are many features that make it easy for developers and developers alike to learn and use Python and other languages in order to improve their codebase, while also allowing them to easily access the source code of their applications.\n",
      "\n",
      "The Python Language\n",
      "Python is the most popular language in the world, with over 1.5 billion users worldwide, making it one of the fastest-growing languages on the planet. Its popularity is due in part to its ease of use, ease\n"
     ]
    }
   ],
   "source": [
    "# Encode input text\n",
    "input_text = \"Explain me about python programming\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate output\n",
    "output = model.generate(input_ids, max_length=256, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_path = \"./app/models/trained_model.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
